
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiple regression &#8212; Coding for Data - 2020 edition</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://matthew-brett.github.io/cfd2020/classification/Multiple_Regression.html" />
    <link rel="shortcut icon" href="../_static/dsfe_favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Simple and multiple regression" href="single_multiple.html" />
    <link rel="prev" title="Accuracy of the classifier" href="Accuracy_of_the_Classifier.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://matthew-brett.github.io/cfd2020/classification/Multiple_Regression.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Multiple regression" />
<meta property="og:description" content="Multiple regression  Note  This page has content from the Multiple_Regression notebook of an older version of the UC Berkeley data science course. See the Berke" />
<meta property="og:image"       content="https://matthew-brett.github.io/cfd2020/_static/dsfe_logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/dsfe_logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Coding for Data - 2020 edition</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Coding for data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/what-is-data-science.html">
   What is data science?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/why-data-science.html">
   Why Data Science?
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../intro/tools_techniques.html">
   Tools and techniques
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/computational-tools.html">
     Computational Tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/statistical-techniques.html">
     Statistical Techniques
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../intro/text-is-data.html">
   Text is data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Plotting_the_Classics.html">
     Plotting the classics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Literary_Characters.html">
     Literary characters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Another_Kind_Of_Character.html">
     Another kind of character
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/surviving_computers.html">
   Surviving the computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/the_software.html">
   Our tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/using_jupyter.html">
   Using Jupyter notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/more_on_jupyter.html">
   More on the Jupyter notebook
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  On code
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/to_code.html">
   Ode to code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/sampling_problem.html">
   A sampling problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/three_girls.html">
   A simpler problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/variables_intro.html">
   Introduction to variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Names.html">
   Names and variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Expressions.html">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/functions.html">
   Introduction to functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Calls.html">
   Call expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/first_pass_three_girls.html">
   A first pass at the simple problem
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data types
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/data_types.html">
   Types of things
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Numbers.html">
   Numbers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Strings.html">
   Strings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/strings_and_variables.html">
   Strings, variables and expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/String_Methods.html">
   String methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Comparison.html">
   Comparisons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/lists.html">
   Lists
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Arrays
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/Arrays.html">
   Arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/Ranges.html">
   Ranges
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/More_on_Arrays.html">
   More on Arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/array_indexing.html">
   Selecting values from an array
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/filling_arrays.html">
   Making and filling arrays.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/function_arguments.html">
   Function arguments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/boolean_arrays.html">
   Boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/leaping_ahead.html">
   Leaping ahead
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Iteration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/iteration.html">
   Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/indentation.html">
   Indentation, indentation, indentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/reply_supreme.html">
   Reply to the Supreme Court
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/inference.html">
   Inference
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data frames
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/boolean_indexing.html">
   Indexing with Boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/data_frames.html">
   Data frames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/data_frame_intro.html">
   Introduction to data frames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/df_series_arrays.html">
   Data frames, Series and arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/missing_values.html">
   Missing values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/df_plotting.html">
   Pandas plotting methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Population and permutation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation.html">
   Populations and permutations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/population_permutation.html">
   Population and permutation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/brexit_ages.html">
   Brexit and ages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation_idea.html">
   The idea of permutation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation_and_t_test.html">
   Permutation and the t-test
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  More building blocks
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/more_building_blocks.html">
   More building blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/introducing_functions.html">
   Introducing Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/none.html">
   On None
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/conditional_statements.html">
   Conditional Statements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/functions_as_values.html">
   Functions as values
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Pandas, indices and labels
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/pandas_indexing.html">
   Indexing in Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/noble_politics.html">
   Noble politics and comparing counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/safe_pandas.html">
   Handling Pandas safely
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/text_encoding.html">
   Storing and loading text
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/numbers_and_strings.html">
   Numbers and strings
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The mean and straight lines
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean.html">
   The mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean_meaning.html">
   The meaning of the mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/where_and_argmin.html">
   Where and argmin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean_and_slopes.html">
   The mean and slopes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/where_2d.html">
   Where in 2D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/finding_lines.html">
   Finding lines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/using_minimize.html">
   Using minimize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/inference_on_slopes.html">
   Inference on slopes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/combining_boolean_arrays.html">
   Combining boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/standard_scores.html">
   Standard scores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/Correlation.html">
   Correlation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Nearest_Neighbors.html">
   Nearest neighbors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Training_and_Testing.html">
   Training and testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Rows_of_Tables.html">
   Rows of tables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Implementing_the_Classifier.html">
   Implementing the classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Accuracy_of_the_Classifier.html">
   Accuracy of the classifier
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Multiple regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="single_multiple.html">
   Simple and multiple regression
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The end of the beginning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../end/end_of_beginning.html">
   The end of the beginning
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/classification/Multiple_Regression.Rmd"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.Rmd</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/matthew-brett/cfd2020"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/matthew-brett/cfd2020/issues/new?title=Issue%20on%20page%20%2Fclassification/Multiple_Regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/matthew-brett/cfd2020/edit/master/classification/Multiple_Regression.Rmd"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/matthew-brett/cfd2020/master?urlpath=tree/classification/Multiple_Regression.Rmd"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://uobhub.org/hub/user-redirect/git-pull?repo=https://github.com/matthew-brett/cfd2020&urlpath=tree/cfd2020/classification/Multiple_Regression.Rmd&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#home-prices">
   Home Prices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation">
     Correlation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-linear-regression">
   Multiple Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#least-squares-regression">
     Least Squares Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-multiple-regression">
     Interpreting Multiple Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nearest-neighbors-for-regression">
   Nearest Neighbors for Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     Evaluation
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="multiple-regression">
<h1>Multiple regression<a class="headerlink" href="#multiple-regression" title="Permalink to this headline">¶</a></h1>
<p><div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page has content from the <a class="reference external" href="https://github.com/data-8/textbook/blob/64b20f0/notebooks/Multiple_Regression.ipynb">Multiple_Regression</a> notebook of an older version of the <a class="reference external" href="https://inferentialthinking.com">UC Berkeley data science course</a>. See the Berkeley course section of the <a class="reference external" href="https://matthew-brett.github.io/cfd2020/license">license file</a>.</p>
</div>
</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># Safe settings for Pandas.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;mode.chained_assignment&#39;</span><span class="p">,</span> <span class="s1">&#39;raise&#39;</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">standard_units</span><span class="p">(</span><span class="n">any_numbers</span><span class="p">):</span>
    <span class="s2">&quot;Convert any array of numbers to standard units.&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">any_numbers</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">any_numbers</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">any_numbers</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">correlation</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">standard_units</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="o">*</span> <span class="n">standard_units</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">y</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have explored ways to use multiple attributes to predict a
categorical variable, let us return to predicting a quantitative variable.
Predicting a numerical quantity is called regression, and a commonly used
method to use multiple attributes for regression is called <em>multiple linear
regression</em>.</p>
<div class="section" id="home-prices">
<h2>Home Prices<a class="headerlink" href="#home-prices" title="Permalink to this headline">¶</a></h2>
<p>The following dataset of house prices and attributes was collected over several
years for the city of Ames, Iowa. A <a class="reference external" href="http://ww2.amstat.org/publications/jse/v19n3/decock.pdf">description of the dataset appears
online</a>. We will focus
only a subset of the columns. We will try to predict the sale price column from
the other columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_sales</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;house.csv&#39;</span><span class="p">)</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">all_sales</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">all_sales</span><span class="p">[</span><span class="s1">&#39;Bldg Type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;1Fam&#39;</span><span class="p">,</span>
                      <span class="n">all_sales</span><span class="p">[</span><span class="s1">&#39;Sale Condition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Normal&#39;</span><span class="p">),</span>
    <span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">,</span> <span class="s1">&#39;1st Flr SF&#39;</span><span class="p">,</span> <span class="s1">&#39;2nd Flr SF&#39;</span><span class="p">,</span>
     <span class="s1">&#39;Total Bsmt SF&#39;</span><span class="p">,</span> <span class="s1">&#39;Garage Area&#39;</span><span class="p">,</span>
     <span class="s1">&#39;Wood Deck SF&#39;</span><span class="p">,</span> <span class="s1">&#39;Open Porch SF&#39;</span><span class="p">,</span> <span class="s1">&#39;Lot Area&#39;</span><span class="p">,</span>
     <span class="s1">&#39;Year Built&#39;</span><span class="p">,</span> <span class="s1">&#39;Yr Sold&#39;</span><span class="p">]]</span>
<span class="n">sales</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SalePrice</th>
      <th>1st Flr SF</th>
      <th>2nd Flr SF</th>
      <th>Total Bsmt SF</th>
      <th>Garage Area</th>
      <th>Wood Deck SF</th>
      <th>Open Porch SF</th>
      <th>Lot Area</th>
      <th>Year Built</th>
      <th>Yr Sold</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2843</th>
      <td>35000</td>
      <td>498</td>
      <td>0</td>
      <td>498.0</td>
      <td>216.0</td>
      <td>0</td>
      <td>0</td>
      <td>8088</td>
      <td>1922</td>
      <td>2006</td>
    </tr>
    <tr>
      <th>1901</th>
      <td>39300</td>
      <td>334</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>5000</td>
      <td>1946</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>1555</th>
      <td>40000</td>
      <td>649</td>
      <td>668</td>
      <td>649.0</td>
      <td>250.0</td>
      <td>0</td>
      <td>54</td>
      <td>8500</td>
      <td>1920</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>708</th>
      <td>45000</td>
      <td>612</td>
      <td>0</td>
      <td>0.0</td>
      <td>308.0</td>
      <td>0</td>
      <td>0</td>
      <td>5925</td>
      <td>1940</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>1220</th>
      <td>52000</td>
      <td>729</td>
      <td>0</td>
      <td>270.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>4130</td>
      <td>1935</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2450</th>
      <td>584500</td>
      <td>1933</td>
      <td>1567</td>
      <td>1733.0</td>
      <td>959.0</td>
      <td>870</td>
      <td>86</td>
      <td>17242</td>
      <td>1993</td>
      <td>2006</td>
    </tr>
    <tr>
      <th>432</th>
      <td>610000</td>
      <td>2674</td>
      <td>0</td>
      <td>2630.0</td>
      <td>762.0</td>
      <td>360</td>
      <td>50</td>
      <td>13693</td>
      <td>2007</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>1063</th>
      <td>615000</td>
      <td>2470</td>
      <td>0</td>
      <td>2535.0</td>
      <td>789.0</td>
      <td>154</td>
      <td>65</td>
      <td>12720</td>
      <td>2003</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>2445</th>
      <td>625000</td>
      <td>1831</td>
      <td>1796</td>
      <td>1930.0</td>
      <td>807.0</td>
      <td>361</td>
      <td>76</td>
      <td>35760</td>
      <td>1995</td>
      <td>2006</td>
    </tr>
    <tr>
      <th>1767</th>
      <td>755000</td>
      <td>2444</td>
      <td>1872</td>
      <td>2444.0</td>
      <td>832.0</td>
      <td>382</td>
      <td>50</td>
      <td>21535</td>
      <td>1994</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
<p>2002 rows × 10 columns</p>
</div></div></div>
</div>
<p>A histogram of sale prices shows a large amount of variability and a
distribution that is clearly not normal. A long tail to the right contains a
few houses that had very high prices. The short left tail does not contain any
houses that sold for less than $35,000.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sales</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Multiple_Regression_6_0.png" src="../_images/Multiple_Regression_6_0.png" />
</div>
</div>
<div class="section" id="correlation">
<h3>Correlation<a class="headerlink" href="#correlation" title="Permalink to this headline">¶</a></h3>
<p>No single attribute is sufficient to predict the sale price. For example, the area of first floor, measured in square feet, correlates with sale price but only explains some of its variability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sales</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;1st Flr SF&#39;</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;1st Flr SF&#39;, ylabel=&#39;SalePrice&#39;&gt;
</pre></div>
</div>
<img alt="../_images/Multiple_Regression_8_1.png" src="../_images/Multiple_Regression_8_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">correlation</span><span class="p">(</span><span class="n">sales</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">,</span> <span class="s1">&#39;1st Flr SF&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6424662541030225
</pre></div>
</div>
</div>
</div>
<p>In fact, none of the individual attributes have a correlation with sale price that is above 0.7 (except for the sale price itself).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">sales</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">sales</span><span class="p">,</span> <span class="n">col_name</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correlation of </span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s1"> and SalePrice:</span><span class="se">\t</span><span class="si">{</span><span class="n">r</span><span class="si">:</span><span class="s1">0.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation of SalePrice and SalePrice:	1.000
Correlation of 1st Flr SF and SalePrice:	0.642
Correlation of 2nd Flr SF and SalePrice:	0.358
Correlation of Total Bsmt SF and SalePrice:	0.653
Correlation of Garage Area and SalePrice:	0.639
Correlation of Wood Deck SF and SalePrice:	0.353
Correlation of Open Porch SF and SalePrice:	0.337
Correlation of Lot Area and SalePrice:	0.291
Correlation of Year Built and SalePrice:	0.565
Correlation of Yr Sold and SalePrice:	0.026
</pre></div>
</div>
</div>
</div>
<p>However, combining attributes can provide higher correlation. In particular, if we sum the first floor and second floor areas, the result has a higher correlation than any single attribute alone.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_both</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">with_both</span><span class="p">[</span><span class="s1">&#39;Both Floors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sales</span><span class="p">[</span><span class="s1">&#39;1st Flr SF&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">sales</span><span class="p">[</span><span class="s1">&#39;2nd Flr SF&#39;</span><span class="p">]</span>
<span class="n">correlation</span><span class="p">(</span><span class="n">with_both</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">,</span> <span class="s1">&#39;Both Floors&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7821920556134877
</pre></div>
</div>
</div>
</div>
<p>This high correlation indicates that we should try to use more than one attribute to predict the sale price. In a dataset with multiple observed attributes and a single numerical value to be predicted (the sale price in this case), multiple linear regression can be an effective technique.</p>
</div>
</div>
<div class="section" id="multiple-linear-regression">
<h2>Multiple Linear Regression<a class="headerlink" href="#multiple-linear-regression" title="Permalink to this headline">¶</a></h2>
<p>In multiple linear regression, a numerical output is predicted from numerical input attributes by multiplying each attribute value by a different slope, then summing the results. In this example, the slope for the <code class="docutils literal notranslate"><span class="pre">1st</span> <span class="pre">Flr</span> <span class="pre">SF</span></code> would represent the dollars per square foot of area on the first floor of the house that should be used in our prediction.</p>
<p>Before we begin prediction, we split our data randomly into a training and test set of equal size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sales</span><span class="p">)</span>
<span class="n">half_N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># Shuffle data frame by taking random sample with same number of rows.</span>
<span class="n">shuffled_sales</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">shuffled_sales</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">half_N</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">shuffled_sales</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">half_N</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="s1">&#39;training and&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">),</span> <span class="s1">&#39;test instances.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1001 training and 1001 test instances.
</pre></div>
</div>
</div>
</div>
<p>The slopes in multiple regression is an array that has one slope value for each attribute in an example. Predicting the sale price involves multiplying each attribute by the slope and summing the result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">slopes</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>

<span class="n">example_row</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Predicting sale price for:&#39;</span><span class="p">,</span> <span class="n">example_row</span><span class="p">)</span>
<span class="n">example_slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">example_row</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using slopes:&#39;</span><span class="p">,</span> <span class="n">example_slopes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Result:&#39;</span><span class="p">,</span> <span class="n">predict</span><span class="p">(</span><span class="n">example_slopes</span><span class="p">,</span> <span class="n">example_row</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicting sale price for: 1st Flr SF        819.0
2nd Flr SF        784.0
Total Bsmt SF     784.0
Garage Area       599.0
Wood Deck SF        0.0
Open Porch SF     217.0
Lot Area         9650.0
Year Built       1923.0
Yr Sold          2008.0
Name: 1530, dtype: float64
Using slopes: [10.08267736  9.18922839  9.32634424 10.93991746 10.44666393 11.35823637
  9.33107718 10.65500604 11.53989575]
Result: 165498.25165596674
</pre></div>
</div>
</div>
</div>
<p>The result is an estimated sale price, which can be compared to the actual sale price to assess whether the slopes provide accurate predictions. Since the <code class="docutils literal notranslate"><span class="pre">example_slopes</span></code> above were chosen at random, we should not expect them to provide accurate predictions at all.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Actual sale price:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Predicted sale price using random slopes:&#39;</span><span class="p">,</span> <span class="n">predict</span><span class="p">(</span><span class="n">example_slopes</span><span class="p">,</span> <span class="n">example_row</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Actual sale price: 138000
Predicted sale price using random slopes: 165498.25165596674
</pre></div>
</div>
</div>
</div>
<div class="section" id="least-squares-regression">
<h3>Least Squares Regression<a class="headerlink" href="#least-squares-regression" title="Permalink to this headline">¶</a></h3>
<p>The next step in performing multiple regression is to define the least squares objective. We perform the prediction for each row in the training set, and then compute the root mean squared error (RMSE) of the predictions from the actual prices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_prices</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span>
<span class="n">train_attributes</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">attributes</span><span class="p">,</span> <span class="n">prices</span><span class="p">):</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prices</span><span class="p">)):</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">attributes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">actual</span> <span class="o">=</span> <span class="n">prices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">predicted</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">errors</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">rmse_train</span><span class="p">(</span><span class="n">slopes</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rmse</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">train_attributes</span><span class="p">,</span> <span class="n">train_prices</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE of all training examples using random slopes:&#39;</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">(</span><span class="n">example_slopes</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSE of all training examples using random slopes: 70148.68590003051
</pre></div>
</div>
</div>
</div>
<p>Finally, we use the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> function to find the slopes with the lowest RMSE. Computation of the best slopes may take several minutes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_slopes</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">rmse_train</span><span class="p">,</span> <span class="n">example_slopes</span><span class="p">)</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The best slopes for the training set:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE of all training examples using the best slopes:&#39;</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">(</span><span class="n">best_slopes</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">best_slopes</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">train_attributes</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interpreting-multiple-regression">
<h3>Interpreting Multiple Regression<a class="headerlink" href="#interpreting-multiple-regression" title="Permalink to this headline">¶</a></h3>
<p>Let’s interpret these results. The best slopes give us a method for estimating the price of a house from its attributes. A square foot of area on the first floor is worth about 80 USD (the first slope), while one on the second floor is worth about 75 USD (the second slope). The final negative value describes the market: prices in later years were lower on average.</p>
<p>The RMSE of around 30,000 USD means that our best linear prediction of the sale price based on all of the attributes is off by around 30,000 USD on the training set, on average.  We find a similar error when predicting prices on the test set, which indicates that our prediction method will generalize to other samples from the same population.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_prices</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span>
<span class="n">test_attributes</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">rmse_test</span><span class="p">(</span><span class="n">slopes</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rmse</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">test_attributes</span><span class="p">,</span> <span class="n">test_prices</span><span class="p">)</span>

<span class="n">rmse_linear</span> <span class="o">=</span> <span class="n">rmse_test</span><span class="p">(</span><span class="n">best_slopes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set RMSE for multiple linear regression:&#39;</span><span class="p">,</span> <span class="n">rmse_linear</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If the predictions were perfect, then a scatter plot of the predicted and actual values would be a straight line with slope 1. We see that most dots fall near that line, but there is some error in the predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">best_slopes</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>

<span class="n">fitted</span> <span class="o">=</span> <span class="n">test_attributes</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">test_prices</span><span class="p">)</span>
<span class="c1"># Plot x=y line.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">5e5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">5e5</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>A residual plot for multiple regression typically compares the errors (residuals) to the actual values of the predicted variable. We see in the residual plot below that we have systematically underestimated the value of expensive houses, shown by the many positive residual values on the right side of the graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">test_prices</span><span class="p">,</span> <span class="n">test_prices</span> <span class="o">-</span> <span class="n">fitted</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">7e5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>As with simple linear regression, interpreting the result of a predictor is at least as important as making predictions. There are many lessons about interpreting multiple regression that are not included in this textbook. A natural next step after completing this text would be to study linear modeling and regression in further depth.</p>
</div>
</div>
<div class="section" id="nearest-neighbors-for-regression">
<h2>Nearest Neighbors for Regression<a class="headerlink" href="#nearest-neighbors-for-regression" title="Permalink to this headline">¶</a></h2>
<p>Another approach to predicting the sale price of a house is to use the price of similar houses. This <em>nearest neighbor</em> approach is very similar to our classifier. To speed up computation, we will only use the attributes that had the highest correlation with the sale price in our original analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_nn</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="n">test_nn</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="n">train_nn</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The computation of closest neighbors is identical to a nearest-neighbor classifier. In this case, we will exclude the <code class="docutils literal notranslate"><span class="pre">'SalePrice'</span></code> rather than the <code class="docutils literal notranslate"><span class="pre">'Class'</span></code> column from the distance computation. The five nearest neighbors of the first test row are shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">pt1</span><span class="p">,</span> <span class="n">pt2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The distance between two points, represented as arrays.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">((</span><span class="n">pt1</span> <span class="o">-</span> <span class="n">pt2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">row_distance</span><span class="p">(</span><span class="n">row1</span><span class="p">,</span> <span class="n">row2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The distance between two rows of a table.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">distance</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row2</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">distances</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the distance from example for each row in training.&quot;&quot;&quot;</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">distance_from_example</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">row_distance</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">example</span><span class="p">)</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">out</span><span class="p">[</span><span class="s1">&#39;Distance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attributes</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">distance_from_example</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="k">def</span> <span class="nf">closest</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a table of the k closest neighbors to example.&quot;&quot;&quot;</span>
    <span class="n">dist_df</span> <span class="o">=</span> <span class="n">distances</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="n">example_nn_row</span> <span class="o">=</span> <span class="n">test_nn</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">closest</span><span class="p">(</span><span class="n">train_nn</span><span class="p">,</span> <span class="n">example_nn_row</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>One simple method for predicting the price is to average the prices of the nearest neighbors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_nn</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return average of the price across the 5 nearest neighbors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">five_nearest</span> <span class="o">=</span> <span class="n">closest</span><span class="p">(</span><span class="n">train_nn</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">five_nearest</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">])</span>

<span class="n">predict_nn</span><span class="p">(</span><span class="n">example_nn_row</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we can inspect whether our prediction is close to the true sale price for our one test example. Looks reasonable!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Actual sale price:&#39;</span><span class="p">,</span> <span class="n">test_nn</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Predicted sale price using nearest neighbors:&#39;</span><span class="p">,</span> <span class="n">predict_nn</span><span class="p">(</span><span class="n">example_nn_row</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>To evaluate the performance of this approach for the whole test set, we apply <code class="docutils literal notranslate"><span class="pre">predict_nn</span></code> to each test example, then compute the root mean squared error of the predictions. Computation of the predictions may take several minutes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">attributes</span> <span class="o">=</span> <span class="n">test_nn</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">)</span>
<span class="n">nn_test_predictions</span> <span class="o">=</span> <span class="n">attributes</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">predict_nn</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rmse_nn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">test_prices</span> <span class="o">-</span> <span class="n">nn_test_predictions</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set RMSE for multiple linear regression: &#39;</span><span class="p">,</span> <span class="n">rmse_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set RMSE for nearest neighbor regression:&#39;</span><span class="p">,</span> <span class="n">rmse_nn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For these data, the errors of the two techniques are quite similar! For different data sets, one technique might outperform another. By computing the RMSE of both techniques on the same data, we can compare methods fairly. One note of caution: the difference in performance might not be due to the technique at all; it might be due to the random variation due to sampling the training and test sets in the first place.</p>
<p>Finally, we can draw a residual plot for these predictions. We still underestimate the prices of the most expensive houses, but the bias does not appear to be as systematic. However, fewer residuals are very close to zero, indicating that fewer prices were predicted with very high accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">test_prices</span><span class="p">,</span> <span class="n">test_prices</span> <span class="o">-</span> <span class="n">nn_test_predictions</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">7e5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page has content from the <a class="reference external" href="https://github.com/data-8/textbook/blob/64b20f0/notebooks/Multiple_Regression.ipynb">Multiple_Regression</a> notebook of an older version of the <a class="reference external" href="https://inferentialthinking.com">UC Berkeley data science course</a>. See the Berkeley course section of the <a class="reference external" href="https://matthew-brett.github.io/cfd2020/license">license file</a>.</p>
</div>
</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "matthew-brett/cfd2020",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="Accuracy_of_the_Classifier.html" title="previous page">Accuracy of the classifier</a>
    <a class='right-next' id="next-link" href="single_multiple.html" title="next page">Simple and multiple regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Matthew Brett, Ani Adhikari, John Denero, David Wagner<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>