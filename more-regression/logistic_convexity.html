
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>What’s wrong with sum of squares for logistic regression? &#8212; Coding for Data - 2020 edition</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://matthew-brett.github.io/cfd2020/more-regression/logistic_convexity.html" />
    <link rel="shortcut icon" href="../_static/dsfe_favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://matthew-brett.github.io/cfd2020/more-regression/logistic_convexity.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="What’s wrong with sum of squares for logistic regression?" />
<meta property="og:description" content="What’s wrong with sum of squares for logistic regression?  import numpy as np import pandas as pd # Safe settings for Pandas. pd.set_option(&#39;mode.chained_assign" />
<meta property="og:image"       content="https://matthew-brett.github.io/cfd2020/_static/dsfe_logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/dsfe_logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Coding for Data - 2020 edition</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Coding for data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/what-is-data-science.html">
   What is data science?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/why-data-science.html">
   Why Data Science?
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../intro/tools_techniques.html">
   Tools and techniques
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/computational-tools.html">
     Computational Tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/statistical-techniques.html">
     Statistical Techniques
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../intro/text-is-data.html">
   Text is data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Plotting_the_Classics.html">
     Plotting the classics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Literary_Characters.html">
     Literary characters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/Another_Kind_Of_Character.html">
     Another kind of character
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/surviving_computers.html">
   Surviving the computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/the_software.html">
   Our tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/using_jupyter.html">
   Using Jupyter notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/more_on_jupyter.html">
   More on the Jupyter notebook
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  On code
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/to_code.html">
   Ode to code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/sampling_problem.html">
   A sampling problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/three_girls.html">
   A simpler problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/variables_intro.html">
   Introduction to variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Names.html">
   Names and variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Expressions.html">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/functions.html">
   Introduction to functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/Calls.html">
   Call expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../code-basics/first_pass_three_girls.html">
   A first pass at the simple problem
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data types
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/data_types.html">
   Types of things
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Numbers.html">
   Numbers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Strings.html">
   Strings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/strings_and_variables.html">
   Strings, variables and expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/String_Methods.html">
   String methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/Comparison.html">
   Comparisons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-types/lists.html">
   Lists
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Arrays
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/Arrays.html">
   Arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/Ranges.html">
   Ranges
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/More_on_Arrays.html">
   More on Arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/array_indexing.html">
   Selecting values from an array
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/filling_arrays.html">
   Making and filling arrays.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/function_arguments.html">
   Function arguments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/boolean_arrays.html">
   Boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../arrays/leaping_ahead.html">
   Leaping ahead
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Iteration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/iteration.html">
   Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/indentation.html">
   Indentation, indentation, indentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/reply_supreme.html">
   Reply to the Supreme Court
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../iteration/inference.html">
   Inference
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data frames
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/boolean_indexing.html">
   Indexing with Boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/data_frames.html">
   Data frames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/data_frame_intro.html">
   Introduction to data frames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/df_series_arrays.html">
   Data frames, Series and arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/missing_values.html">
   Missing values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-frames/df_plotting.html">
   Pandas plotting methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Population and permutation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation.html">
   Populations and permutations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/population_permutation.html">
   Population and permutation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/brexit_ages.html">
   Brexit and ages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation_idea.html">
   The idea of permutation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../permutation/permutation_and_t_test.html">
   Permutation and the t-test
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  More building blocks
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/more_building_blocks.html">
   More building blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/introducing_functions.html">
   Introducing Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/none.html">
   On None
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/conditional_statements.html">
   Conditional Statements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../functions-conditionals/functions_as_values.html">
   Functions as values
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Pandas, indices and labels
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/pandas_indexing.html">
   Indexing in Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/noble_politics.html">
   Noble politics and comparing counts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/safe_pandas.html">
   Handling Pandas safely
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/text_encoding.html">
   Storing and loading text
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wild-pandas/numbers_and_strings.html">
   Numbers and strings
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The mean and straight lines
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean.html">
   The mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean_meaning.html">
   The meaning of the mean
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/where_and_argmin.html">
   Where and argmin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/mean_and_slopes.html">
   The mean and slopes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/where_2d.html">
   Where in 2D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/finding_lines.html">
   Finding lines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/using_minimize.html">
   Using minimize
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/inference_on_slopes.html">
   Inference on slopes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/combining_boolean_arrays.html">
   Combining boolean arrays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/standard_scores.html">
   Standard scores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mean-slopes/Correlation.html">
   Correlation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Nearest_Neighbors.html">
   Nearest neighbors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Training_and_Testing.html">
   Training and testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Rows_of_Tables.html">
   Rows of tables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Implementing_the_Classifier.html">
   Implementing the classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Accuracy_of_the_Classifier.html">
   Accuracy of the classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/Multiple_Regression.html">
   Multiple regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/single_multiple.html">
   Simple and multiple regression
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Useful pandas
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../useful-pandas/crosstab.html">
   Cross-tabulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../useful-pandas/groupby.html">
   The power of groupby
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../useful-pandas/merge.html">
   Merging
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  More on regression
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="logistic_regression.html">
   Logistic regression
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Confidence
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/bootstrap.html">
   The Bootstrap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/havana_math.html">
   A problem for the education minister
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/Central_Limit_Theorem.html">
   The Central Limit Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/first_bayes.html">
   First Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/bayes_bars.html">
   Bayes and bars
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../confidence/second_bayes.html">
   Back to Bayes
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The end of the beginning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../end/end_of_beginning.html">
   The end of the beginning
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/more-regression/logistic_convexity.Rmd"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.Rmd</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/matthew-brett/cfd2020"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/matthew-brett/cfd2020/issues/new?title=Issue%20on%20page%20%2Fmore-regression/logistic_convexity.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/matthew-brett/cfd2020/edit/master/more-regression/logistic_convexity.Rmd"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/matthew-brett/cfd2020/master?urlpath=tree/more-regression/logistic_convexity.Rmd"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://uobhub.org/hub/user-redirect/git-pull?repo=https://github.com/matthew-brett/cfd2020&urlpath=tree/cfd2020/more-regression/logistic_convexity.Rmd&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-background-the-data">
   The background, the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression-the-crude-approach">
   Linear regression - the crude approach
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sigmoid-prediction-with-sum-of-squares-error">
   Sigmoid prediction with sum of squares error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#back-to-maximum-likelihood">
   Back to maximum likelihood
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#another-example">
   Another example
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="what-s-wrong-with-sum-of-squares-for-logistic-regression">
<h1>What’s wrong with sum of squares for logistic regression?<a class="headerlink" href="#what-s-wrong-with-sum-of-squares-for-logistic-regression" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># Safe settings for Pandas.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;mode.chained_assignment&#39;</span><span class="p">,</span> <span class="s1">&#39;raise&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># Make the plots look more fancy.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="c1"># Optimization function</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</pre></div>
</div>
</div>
</div>
<p>This page gives some extra explanation for the
<a class="reference internal" href="logistic_regression.html"><span class="doc std std-doc">logistic_regression</span></a> page.</p>
<p>Here we say more about why we might prefer the Maximum Likelihood Estimate way
of scoring potential fits to the data, to our more usual least squared error.
If you want the gory details on this choice, see <a class="reference external" href="https://stats.stackexchange.com/a/254067">this answer on
StackOverflow</a>. Here we look at
whether this the sum of squares works well with <code class="docutils literal notranslate"><span class="pre">minimize</span></code>.  The discussion in
this page corresponds to the “computational efficiency” section of the answer
linked above.</p>
<div class="section" id="the-background-the-data">
<h2>The background, the data<a class="headerlink" href="#the-background-the-data" title="Permalink to this headline">¶</a></h2>
<p>In that page we were trying to looking at the <a class="reference internal" href="../data/chronic_kidney_disease.html"><span class="doc std std-doc">chronic kidney disease
dataset</span></a>, to see if we good predict whether a
patient had “good” appetite (as opposed to “poor” appetite) given that patient’s blood hemoglobin concentration.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;ckd_clean.csv&#39;</span><span class="p">)</span>
<span class="c1"># Our columns of interest.</span>
<span class="n">hgb_app</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;Hemoglobin&#39;</span><span class="p">,</span> <span class="s1">&#39;Appetite&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># Dummy value column containing 0 for &quot;poor&quot; Appetite, 1 for &quot;good&quot;.</span>
<span class="n">hgb_app</span><span class="p">[</span><span class="s1">&#39;appetite_dummy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hgb_app</span><span class="p">[</span><span class="s1">&#39;Appetite&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="p">[</span><span class="s1">&#39;poor&#39;</span><span class="p">,</span> <span class="s1">&#39;good&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">hgb_app</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hemoglobin</th>
      <th>Appetite</th>
      <th>appetite_dummy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>11.2</td>
      <td>poor</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.5</td>
      <td>poor</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10.8</td>
      <td>poor</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.6</td>
      <td>poor</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.7</td>
      <td>poor</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We take out the columns we are interested in for our further use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The x (predictor) and y (to-be-predicted) variables.</span>
<span class="n">hemoglobin</span> <span class="o">=</span> <span class="n">hgb_app</span><span class="p">[</span><span class="s1">&#39;Hemoglobin&#39;</span><span class="p">]</span>
<span class="n">appetite_d</span> <span class="o">=</span> <span class="n">hgb_app</span><span class="p">[</span><span class="s1">&#39;appetite_dummy&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a plot of the 0 / 1 appetite values</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_hgb_app</span><span class="p">():</span>
    <span class="c1"># Build plot, add custom label.</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">hgb_app</span><span class="p">[</span><span class="s1">&#39;Appetite&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="s1">&#39;poor&#39;</span><span class="p">,</span> <span class="s1">&#39;good&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">])</span>
    <span class="n">hgb_app</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;Hemoglobin&#39;</span><span class="p">,</span> <span class="s1">&#39;appetite_dummy&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Appetite</span><span class="se">\n</span><span class="s1">0 = poor, 1 = good&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span>  <span class="c1"># Just label 0 and 1 on the y axis.</span>
    <span class="c1"># Put a custom legend on the plot.  This code is a little obscure.</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;good&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;poor&#39;</span><span class="p">)</span>

<span class="n">plot_hgb_app</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_8_0.png" src="../_images/logistic_convexity_8_0.png" />
</div>
</div>
</div>
<div class="section" id="linear-regression-the-crude-approach">
<h2>Linear regression - the crude approach<a class="headerlink" href="#linear-regression-the-crude-approach" title="Permalink to this headline">¶</a></h2>
<p>The crude and brutal approach to predicting these values is to use simple
least-squares regression.   We can do this in the usual way by using
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> with a function that returns the sum of squared
error between the straight line predictions and the 0 / 1 labels.  Here’s the function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ss_cost</span><span class="p">(</span><span class="n">c_s</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Cost function for sum of squares prediction error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># c_s is a list containing two elements, an intercept and a slope.</span>
    <span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="n">c_s</span>
    <span class="c1"># Values predicted from these x_values, using this intercept and slope.</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">x_values</span> <span class="o">*</span> <span class="n">slope</span>
    <span class="c1"># Difference of prediction from the actual y values.</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">y_values</span> <span class="o">-</span> <span class="n">predicted</span>
    <span class="c1"># Sum of squared error.</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Start with a guess of intercept -0.5, slope 0.1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use cost function with miminize.</span>
<span class="n">mr_ss</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">ss_cost</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">))</span>
<span class="n">mr_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 10.3155095224358
 hess_inv: array([[ 0.07498683, -0.00524735],
       [-0.00524735,  0.00038337]])
      jac: array([-1.19209290e-07,  2.38418579e-07])
  message: &#39;Optimization terminated successfully.&#39;
     nfev: 24
      nit: 4
     njev: 8
   status: 0
  success: True
        x: array([-0.07904106,  0.07004924])
</pre></div>
</div>
</div>
</div>
<p>Store the slope and intercept, predict the values directly from the straight line:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter_ss</span><span class="p">,</span> <span class="n">slope_ss</span> <span class="o">=</span> <span class="n">mr_ss</span><span class="o">.</span><span class="n">x</span>
<span class="n">predicted_ss</span> <span class="o">=</span> <span class="n">inter_ss</span> <span class="o">+</span> <span class="n">slope_ss</span> <span class="o">*</span> <span class="n">hemoglobin</span>
</pre></div>
</div>
</div>
</div>
<p>Show the results:</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Do the base plot of the hemoglobin and appetite_d.</span>
<span class="n">plot_hgb_app</span><span class="p">()</span>

<span class="c1"># A new plot on top of the old.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">predicted_ss</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LR prediction&#39;</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear regression with sum of squares&quot;</span><span class="p">)</span>
<span class="c1"># Show the legend.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_16_0.png" src="../_images/logistic_convexity_16_0.png" />
</div>
</div>
<p>Let us remind ourselves of how the sum of squared error values change as we change the slope and the intercept.  First we hold the slope constant at a fairly bad guess of 0.1, and try different intercepts.  For each intercept we calculate the sum of squared error:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some intercepts to try.</span>
<span class="n">intercepts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">n_inters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">intercepts</span><span class="p">)</span>
<span class="n">ss_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_inters</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_inters</span><span class="p">):</span>
    <span class="n">ss_errors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss_cost</span><span class="p">([</span><span class="n">intercepts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">intercepts</span><span class="p">,</span> <span class="n">ss_errors</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;intercept&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Linear SS error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Errors for different intercepts, slope 0.1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Errors for different intercepts, slope 0.1&#39;)
</pre></div>
</div>
<img alt="../_images/logistic_convexity_18_1.png" src="../_images/logistic_convexity_18_1.png" />
</div>
</div>
<p>Notice the very simple shape of this curve.  It is a parabola, it descends
steeply for values far from the minimum, and more slowly as it gets closer.
This is a curve that <code class="docutils literal notranslate"><span class="pre">minimize</span></code> finds it very easy to work with, because every
time it tries an intercept (in this case), the direction (up, down) of the
curve tells <code class="docutils literal notranslate"><span class="pre">minimize</span></code> what direction to go next.  If the curve is going down
at this point, it should try a larger (more positive) intercept value; if the
curve is going up, it should try a smaller (more negative) intercept. The
up/down-ness of the curve tells <code class="docutils literal notranslate"><span class="pre">minimize</span></code> the right way to go, and this
direction is always correct.  You may also have noticed that this parabola
shape is always the same for these simple least squares functions, like
<code class="docutils literal notranslate"><span class="pre">ss_any_line</span></code>.</p>
<p>Just to illustrate again, here we try holding the intercept constant at a fairly bad guess of 0.5, and vary the slopes.  Notice we get the same helpful parabola shape:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Slopes to try.</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">n_slopes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">slopes</span><span class="p">)</span>
<span class="n">ss_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_slopes</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_slopes</span><span class="p">):</span>
    <span class="n">ss_errors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss_cost</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">slopes</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">slopes</span><span class="p">,</span> <span class="n">ss_errors</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Linear SS error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Errors for different slopes, intercept 0.5&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_20_0.png" src="../_images/logistic_convexity_20_0.png" />
</div>
</div>
<p>These are plots of how the value of the <em>cost function</em> changes as we change
the parameters.  The parabolas we see above are examples of curves that are
<a class="reference external" href="https://en.wikipedia.org/wiki/Convex_function">convex</a>; convex curves like
parabolas are particularly easy and quick for <code class="docutils literal notranslate"><span class="pre">minimize</span></code> to work with.</p>
<p>We will see that using sum of squared error with our preferred sigmoid
prediction generates cost function curves that are a lot more complicated,
making it more difficult for <code class="docutils literal notranslate"><span class="pre">minimize</span></code> to find the best parameters.  If we
give <code class="docutils literal notranslate"><span class="pre">minimize</span></code> a bad initial guess, it can get the answer badly wrong. Put
technically, this is because the cost function curves are not convex.</p>
</div>
<div class="section" id="sigmoid-prediction-with-sum-of-squares-error">
<h2>Sigmoid prediction with sum of squares error<a class="headerlink" href="#sigmoid-prediction-with-sum-of-squares-error" title="Permalink to this headline">¶</a></h2>
<p>For the reasons you saw in the [logistic regression page](logistic
regression), we recoil from the very simple straight line fit above, and
prefer to use a sigmoid curve to fit the 0 / 1 labels.</p>
<p>In that page we defined the functions to convert the straight line predictions
that we want to use with <code class="docutils literal notranslate"><span class="pre">minimize</span></code> and the sigmoid predictions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inv_logit</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Reverse logit transformation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">odds_ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Reverse the log operation.</span>
    <span class="k">return</span> <span class="n">odds_ratios</span> <span class="o">/</span> <span class="p">(</span><span class="n">odds_ratios</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Reverse odds ratios operation.</span>


<span class="k">def</span> <span class="nf">params2pps</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Calculate predicted probabilities of 1 for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Predicted log odds of being in class 1.</span>
    <span class="n">predicted_log_odds</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">inv_logit</span><span class="p">(</span><span class="n">predicted_log_odds</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This allowed us to build our sum of squares logit cost function.  This
function calculates the sum of squares difference from the sigmoid predictions
and the actual 0 / 1 labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ss_logit_cost</span><span class="p">(</span><span class="n">c_s</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">):</span>
    <span class="c1"># Unpack intercept and slope into values.</span>
    <span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="n">c_s</span>
    <span class="c1"># Predicted p values on sigmoid</span>
    <span class="n">pps</span> <span class="o">=</span> <span class="n">params2pps</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">x_values</span><span class="p">)</span>
    <span class="c1"># Prediction errors.</span>
    <span class="n">sigmoid_error</span> <span class="o">=</span> <span class="n">y_values</span> <span class="o">-</span> <span class="n">pps</span>
    <span class="c1"># Sum of squared error</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sigmoid_error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we found our sum of squares best straight line (that corresponds to a
sigmoid after transformation).  Notice that we have started <code class="docutils literal notranslate"><span class="pre">minimize</span></code> with a
guessed intercept of -7 and a guessed slope of 0.8.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mr_ss_logit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">ss_logit_cost</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">))</span>
<span class="n">mr_ss_logit</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 9.621504133676222
 hess_inv: array([[ 6.0509272 , -0.57246015],
       [-0.57246015,  0.05674741]])
      jac: array([-1.19209290e-07,  2.38418579e-07])
  message: &#39;Optimization terminated successfully.&#39;
     nfev: 42
      nit: 12
     njev: 14
   status: 0
  success: True
        x: array([-5.28090451,  0.58493981])
</pre></div>
</div>
</div>
</div>
<p>We can calculate the predicted 0 / 1 labels, and plot them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter_ss_logit</span><span class="p">,</span> <span class="n">slope_ss_logit</span> <span class="o">=</span> <span class="n">mr_ss_logit</span><span class="o">.</span><span class="n">x</span>
<span class="n">predicted_ss_logit</span> <span class="o">=</span> <span class="n">params2pps</span><span class="p">(</span><span class="n">inter_ss_logit</span><span class="p">,</span> <span class="n">slope_ss_logit</span><span class="p">,</span> <span class="n">hemoglobin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_hgb_app</span><span class="p">()</span>
<span class="c1"># A new plot on top of the old.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">predicted_ss_logit</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Logit ss solution&#39;</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="c1"># Show the legend.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_30_0.png" src="../_images/logistic_convexity_30_0.png" />
</div>
</div>
<p>Let us have a look at what the cost function curves look like for the <code class="docutils literal notranslate"><span class="pre">ss_logit_cost</span></code> cost function.  For now, let us look at what happens to the cost function curves as we change the intercept, holding the slope the same.</p>
<p>Because we will do this several times, with various intercepts and constant slopes, we make a function, so we don’t repeat ourselves:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_some_intercepts</span><span class="p">(</span><span class="n">cost_function</span><span class="p">,</span> <span class="n">intercepts</span><span class="p">,</span> <span class="n">slope</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Plot values of `cost_function` for given `intercepts` and `slope`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cost_function : function</span>
<span class="sd">        Function to call to get cost function value, given an intercept and a slope.</span>
<span class="sd">    intercepts : array</span>
<span class="sd">        Array of intercepts for which to calculate cost function.</span>
<span class="sd">    slope : number</span>
<span class="sd">        Slope (held constant for each intercept).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">intercepts</span><span class="p">)</span>
    <span class="n">ss_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="c1"># Calculate and store cost function value for intercept, slope.</span>
        <span class="n">ss_errors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">([</span><span class="n">intercepts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">slope</span><span class="p">],</span>
                                     <span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">intercepts</span><span class="p">,</span> <span class="n">ss_errors</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;intercept&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cost function value&#39;</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Errors for slope = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Remember the attractive parabolas for the cost function curves in the crude
case above, where we were doing simple regression.</p>
<p>In the next cell, we set the slope to the best slope that <code class="docutils literal notranslate"><span class="pre">minimize</span></code>
found, and show the effect on our <code class="docutils literal notranslate"><span class="pre">ss_logit_cost</span></code> function, when varying the intercept.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cost function curve varying intercept between -20 and 5, for best slope.</span>
<span class="n">plot_some_intercepts</span><span class="p">(</span><span class="n">ss_logit_cost</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">slope_ss_logit</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_34_0.png" src="../_images/logistic_convexity_34_0.png" />
</div>
</div>
<p>There is a clear minimum at around -5.2, as we expect from the results above,
but we have lost the nice parabola shape.  For intercepts greater than about
3, the graph is very flat.  This could spell trouble for <code class="docutils literal notranslate"><span class="pre">minimize</span></code>, if it
gets stuck trying a series of intercepts more than 3.  For example, the cost
function will stay almost the same as <code class="docutils literal notranslate"><span class="pre">minimize</span></code> tries values around 5, so
<code class="docutils literal notranslate"><span class="pre">minimize</span></code> may not discover that it needs to track back to the real minimum,
near -5.</p>
<p>It can get even worse when trying slopes that are further away from the
optimum.  In the next plot, we set the slope badly wrong, at 3, and try different intercepts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_some_intercepts</span><span class="p">(</span><span class="n">ss_logit_cost</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_36_0.png" src="../_images/logistic_convexity_36_0.png" />
</div>
</div>
<p>The plot is a strange shape. Again we see a nasty plateau with intercepts
above 0.  If <code class="docutils literal notranslate"><span class="pre">minimize</span></code> is trying intercepts above 0, the cost function may
not vary much, and <code class="docutils literal notranslate"><span class="pre">minimize</span></code> may get stuck on this plateau, for example
concluding the intercept of 6 is as good as any nearby.</p>
<p>An in fact, this does happen if we set very bad starting estimates for
<code class="docutils literal notranslate"><span class="pre">minimize</span></code>.  Here we set the starting intercept to be 6, and the starting
slope to be 2.5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bad_mr_ss_logit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">ss_logit_cost</span><span class="p">,</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span>
                           <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">))</span>
<span class="n">bad_mr_ss_logit</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 18.999997860319507
 hess_inv: array([[1, 0],
       [0, 1]])
      jac: array([2.14576721e-06, 6.67572021e-06])
  message: &#39;Optimization terminated successfully.&#39;
     nfev: 3
      nit: 0
     njev: 1
   status: 0
  success: True
        x: array([6. , 2.5])
</pre></div>
</div>
</div>
</div>
<p>You can see that <code class="docutils literal notranslate"><span class="pre">minimize</span></code> has got stuck on the plateau we saw above and has
given up, simply returning the terrible intercept and slope we sent it.</p>
<p>You can also see that <code class="docutils literal notranslate"><span class="pre">minimize</span></code> did not detect any problems, and returned the
message “Optimization terminated successfully”.</p>
<p>We have this problem because of the irregular shape of the cost-function curve for our cost function, that calculates sum of squared error for the sigmoid predictions.</p>
</div>
<div class="section" id="back-to-maximum-likelihood">
<h2>Back to maximum likelihood<a class="headerlink" href="#back-to-maximum-likelihood" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="logistic_regression.html"><span class="doc std std-doc">logistic_regression</span></a> page proposed an alternative
cost function for the sigmoid predictions - maximum likelihood.  See that page
for details, but here is somewhat cleaned up version the maximum likelihood
cost function from the page above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ml_logit_cost</span><span class="p">(</span><span class="n">intercept_and_slope</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Cost function for maximum likelihood</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="n">intercept_and_slope</span>
    <span class="n">pp1</span> <span class="o">=</span> <span class="n">params2pps</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">p_of_y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">pp1</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pp1</span><span class="p">)</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_of_y</span><span class="p">))</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">log_likelihood</span>
</pre></div>
</div>
</div>
</div>
<p>We find the best intercept and slope using the maximum likelihood (ML).  While
we are at it, we send in the same terrible estimate for the intercept and
slope:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mr_ML</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">ml_logit_cost</span><span class="p">,</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">))</span>
<span class="n">mr_ML</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 29.167993895858697
 hess_inv: array([[ 2.70093935, -0.2506576 ],
       [-0.2506576 ,  0.0242659 ]])
      jac: array([9.53674316e-07, 8.58306885e-06])
  message: &#39;Optimization terminated successfully.&#39;
     nfev: 90
      nit: 13
     njev: 30
   status: 0
  success: True
        x: array([-7.29187128,  0.7991543 ])
</pre></div>
</div>
</div>
</div>
<p>The fit is reasonable:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inter_ML</span><span class="p">,</span> <span class="n">slope_ML</span> <span class="o">=</span> <span class="n">mr_ML</span><span class="o">.</span><span class="n">x</span>
<span class="n">predicted_ML</span> <span class="o">=</span> <span class="n">inv_logit</span><span class="p">(</span><span class="n">inter_ML</span> <span class="o">+</span> <span class="n">slope_ML</span> <span class="o">*</span> <span class="n">hemoglobin</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_hgb_app</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">predicted_ML</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ML prediction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_46_0.png" src="../_images/logistic_convexity_46_0.png" />
</div>
</div>
<p>The ML search by <code class="docutils literal notranslate"><span class="pre">minimize</span></code> is more reliable than the sum-of-squares case
above; it is less dependent on us choosing some reasonable starting values.
This is because the ML cost function is <em>convex</em>. Here is the cost-function
curve for the ML cost function, as we vary the intercept for a fixed slope. We
see that we have a much more predictable curve, that slopes smoothly downwards
to a minimum and smoothly upwards after that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_some_intercepts</span><span class="p">(</span><span class="n">ml_logit_cost</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">slope_ss_logit</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/logistic_convexity_48_0.png" src="../_images/logistic_convexity_48_0.png" />
</div>
</div>
<p>However, this does not mean the ML cost function is infallible.  We can push it to a state where the calculation errors start to overwhelm the values.   However, ML still has the advantage, because, unlike the sum of squares, we do get a warning:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Starting estimates too far off.</span>
<span class="n">minimize</span><span class="p">(</span><span class="n">ml_logit_cost</span><span class="p">,</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">hemoglobin</span><span class="p">,</span> <span class="n">appetite_d</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/mb312/Library/Python/3.8/lib/python/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/Users/mb312/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_numdiff.py:497: RuntimeWarning: invalid value encountered in subtract
  df = fun(x) - f0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: inf
 hess_inv: array([[1, 0],
       [0, 1]])
      jac: array([nan, nan])
  message: &#39;NaN result encountered.&#39;
     nfev: 3
      nit: 0
     njev: 1
   status: 3
  success: False
        x: array([6., 3.])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="another-example">
<h2>Another example<a class="headerlink" href="#another-example" title="Permalink to this headline">¶</a></h2>
<p>You will find another demonstration of this difference between sum of squares
and maximum likelihood in <a class="reference internal" href="logistic_flails.html"><span class="doc std std-doc">this on logistic cost functions</span></a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "matthew-brett/cfd2020",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./more-regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Matthew Brett, Ani Adhikari, John Denero, David Wagner<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>